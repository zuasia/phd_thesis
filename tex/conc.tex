%!TEX root=../paper.tex

\chapter{Conclusion}
\label{sec:conc}

This chapter provides the conclusion of my dissertation work. The retrospective part (\Sec{sec:conc:retro}) summarize my Ph.D. research work and distill some of the important lessons learned during this process. The prospective part (\Sec{sec:conc:pros}) envisions how to apply and generalize this dissertation's research effort into more general computing systems, and provides the author's own remark on how computing will move forward, and how to steer one's research focus as well as the career path at the time this dissertation is written.

\section{Retrospective}
\label{sec:conc:retro}

My dissertation provides comprehensive, measurement-based analysis of a microprocessor's timing margin characteristics under different environmental variation, namely temperature, voltage, and process. The data and insights presented in this thesis is extracted all using in-silicon sensor measurement, thus providing critical guidance on what causes the timing margin to be overprovisioned, how to reclaim it using active timing margin style solution, and how to design system from software to hardware in order to help active timing margin performs the best.

The timing margin problem is admittedly rooted in the microprocessor's circuit level and even device level behavior. Yet, this dissertation shows that to extract the full efficiency, architecture and software level co-design and management that impacts hardware behavior, specifically power consumption which indirectly affects chip temperature and voltage loss, are of significant benefits. Specifically:

For temperature variation (\Sec{sec:temperature}), we identify the huge timing margin slack caused by the significant circuit timing variation in the temperature inversion region and propose a table lookup named based feedback loop, i.e., \tistates, for active timing margin. We note the time scale of temperature variation is typically at the order of ms, so the table storage and lookup action can be put in off-chip hardware, or in system software, such as the OS or device driver. Furthermore, we find that for the system that employs \tistates, high workload temperature can reduce total system power, by balancing leakage power increase with dynamic power decrease. Thus, whole-system management of processor temperature can be in place to reduce total chip power.

For voltage variation/noise, hardware, or circuit level solution is mandatory to deal with the fast-occurring nature of $di/dt$ effects, as is the case of the adaptive clocking system we study in \Sec{sec:voltage} and \Sec{sec:process}. For these systems, we conduct in-depth measurement to understand the mitigation of voltage noise, after a decade of meaningful investigation of its architecture-level causes~\cite{grochowski2002microarchitectural,powell2003pipeline,gupta2007understanding,gupta2008decor,gupta2009event,reddi2009voltage,reddi2010voltage,miller2012vrsync,zhang2014architecture}, and find that, similar to the case of temperature variation, longer-term IR voltage loss caused by application power consumption limits the efficiency improvement we can gain. We propose load-balanced application scheduling to help individual processors achieve its best power saving.

For process variation, it has been long known that each individual core has their own operating frequency~\cite{liang2007process,sarangi2008varius,teodorescu2008variation,rangan2009thread,dighe2010within,rangan2011achieving}, although providing per-core frequency points in a multicore induces substantial test effort and performance variation issues, which is also the reason why existing multicores all employ uniform frequency determined by the slowest core. We explore leveraging the core-level adaptive clocking loop to track individual core's speed, which not only frees up frequency from runtime effects that occasionally erode the timing margin such as temperature and voltage variation but also brings up the fast cores which are suffering from the excess margin, dictated by the slow cores. We further propose application scheduling and throttling mechanism to manage performance variation, in the presence of static frequency heterogeneity caused by core-to-core process variation, as well as the runtime frequency variation caused by power delivery system sharing on these active timing margin systems.

\section{Prospective}
\label{sec:conc:pros}

This dissertation provides an in-depth study on timing margin and its optimization across system stack. Based on commercial hardware measurement, the insights presented thus render itself useful for industrial practice. Although the active timing margin techniques we study are explored on CPU and GPU architectures, they ideally apply to any other platforms. To facilitate ease of adoption, future work can be carried out to put the research fruition in this dissertation into more detail for robust production adoption.

For \tistates, an automatic procedure to build the temperature to voltage conversion table can be implemented and tested. It is worthwhile to understand the max within-die temperature gradient due to local hotspots and its impact of voltage reduction magnitude. It is also worthwhile to understand how different circuit cell types affect the \tistate tables as their threshold voltage varies. For latest 7nm technology, a thorough evaluation is needed to understand to the trade-off between leveraging the device's low leakage power for frequency and performance enhancement, or power reduction which exposes space for temperature management in synergy with \tistates.

For adaptive clocking, or adaptive instruction issue system, an automatic procedure is also needed to speedup per-core timing margin sensor calibration for identifying the safe customization point for ultimate performance. With shared power delivery, application scheduling and throttling are needed for performance management. Alternatively, architecture-level re-design of on-chip power delivery network can also reduce inter-core interference from IR voltage drop loss. Combined with Integrated Voltage Regulators (IVRs), the complete design space is yet to be covered.

Moving forward, the era of general purpose processor performance benefits through Moore's law and Dennard scaling has undoubtedly ended. The future of computing system enhancement will depend on domain-specific accelerator hardware design, accompanying software toolchain design, and convenient tools for low-cost, fast prototyping and testing~\cite{hennessynew}. The timing margin optimizations proposed in this dissertation can be embedded into the resulting system, should ultra power/performance efficiency is demanded. The author believes as a computer architect, identifying key application domains, and shipping the accompanying hardware-software system that is of economic value is a major task for the coming decade.