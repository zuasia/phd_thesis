\select@language {british}
\addvspace {10pt}
\contentsline {figure}{\numberline {1.1}{\ignorespaces Overview of this thesis's cross-layer research on active timing margin management. We characterizes state-of-the art hardware active timing margin mechanisms such as those that deal with fast $di/dt$ effects, proposes software scheduling techniques to aid aid these active timing chips, and draft firmware power management states to augment existing active timing margin techniques.\relax }}{9}{figure.caption.1}
\addvspace {10pt}
\contentsline {figure}{\numberline {2.1}{\ignorespaces Timing margin ensures processor execution correctness by allocating extra room in pipeline's clock cycle time. Timing margin can be delivered by providing extra voltage, known as the voltage guardband, or alternatively slowing down frequency. Safely reducing the timing margin can improve power via undervolting, or improve performance via overclocking.\relax }}{17}{figure.caption.2}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Timing margin is the time left in clock cycle after circuit completes its work.}}}{17}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Voltage guardband}}}{17}{subfigure.1.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Power/Performance saving}}}{17}{subfigure.1.3}
\contentsline {figure}{\numberline {2.2}{\ignorespaces An electrical model of a computer's power delivery subsystem, from the voltage regulator module (VRM) to on-chip transistors. Resistive, capacitive, and inductive impedance exist on this path, adding noise to the voltage delivered to transistors which causes timing uncertainty.\relax }}{21}{figure.caption.3}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Active timing margin is a control loop that detects timing margin and related chip load environment, and accordingly adjust supply voltage or operating frequency in real-time to supply just enough margin.\relax }}{26}{figure.caption.4}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Active timing margin protects $di/dt$ effect by making frequency/clock cycle track supply voltage, which improves performance and reduces timing margin wastage.\relax }}{26}{figure.caption.5}
\addvspace {10pt}
\contentsline {figure}{\numberline {3.1}{\ignorespaces Temperature inversion is having more impact on processor performance as technology scales.\relax }}{29}{figure.caption.6}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Under low voltage, temperature inversion increases circuit performance.}}}{29}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Temperature inversion's inflection voltage approaches nominal supply.}}}{29}{subfigure.1.2}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Die photo of the A10-8700P SoC.\relax }}{32}{figure.caption.7}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Temperature control setup.\relax }}{32}{figure.caption.7}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Power supply monitors (PSMs) measures pipeline speed/timing margin with an inverter ring. By counting how many inverters an edge has traveled through, the PSM reports a digital value that reflects circuit speed.\relax }}{34}{figure.caption.8}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Temperature inversion happens below 0.9~V and is progressively stronger when voltage scales down.\relax }}{36}{figure.caption.9}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Estimating voltage reduction potential based on PSM characterization at different temperatures.\relax }}{38}{figure.caption.10}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Voltage reduction potential is more pronounced in the near-threshold low voltage region.\relax }}{41}{figure.caption.11}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Exploring T$_{i}$-state\xspace at 80$\celsius $\xspace : we measure the ``training'' workloads' timing margin, and choose the $V_{dd}$ that best tracks the standard margin.\relax }}{44}{figure.caption.12}
\contentsline {figure}{\numberline {3.9}{\ignorespaces T$_{i}$-state\xspace undervolting decision at 80$\celsius $\xspace closely tracks the ``golden'' reference runs' timing margin, which is needed for reliability.\relax }}{45}{figure.caption.13}
\contentsline {figure}{\numberline {3.10}{\ignorespaces $V_{dd}$ reduction due to T$_{i}$-states\xspace . The line corresponds to the VRM's quantized output values.\relax }}{47}{figure.caption.15}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Power saving increases at higher temperatures. We mimic workload temperature by externally controlling die temperature to a 40$\celsius $\xspace ~--~80$\celsius $\xspace range. T$_{i}$-state\xspace 's power reduction is independent of the workload activity. \relax }}{48}{figure.caption.16}
\contentsline {figure}{\numberline {3.12}{\ignorespaces Power versus temperature under different scaling factors for different workloads. In FinFET and FD-SOI, T$_{i}$-state\xspace makes GPU power smaller at high temperature. The optimal temperature is different for the workloads and the different scaling settings, and this is because the ratio of static to dynamic power across the workloads varies.\relax }}{52}{figure.caption.18}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Benchmark {\it FFT}}}}{52}{subfigure.12.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Benchmark {\it particlefilter}}}}{52}{subfigure.12.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Benchmark {\it Reduction}}}}{52}{subfigure.12.3}
\contentsline {figure}{\numberline {3.13}{\ignorespaces T$_{i}$-state\xspace temperature and voltage control: two loops work in synergy to minimize power. Loop~1 is a fast control loop that uses T$_{i}$-state\xspace table to keep adjusting voltage in response to silicon temperature variation. Loop~2 is a slow control loop that sets the optimal temperature based on workload steady-state dynamic power profile.\relax }}{55}{figure.caption.19}
\addvspace {10pt}
\contentsline {figure}{\numberline {4.1}{\ignorespaces In POWER7+, Critical Path Monitor (CPM), Digital Phase Locked Loop (DPLL), and off-chip voltage controller work synergistically to let active timing margin provide just enough margin~\cite {lefurgy2013active}.\relax }}{62}{figure.caption.20}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Critical path monitors (CPMs) are distributed across the chip to measure spatially variant timing margin consumption, caused by local voltage noise and other system effects.\relax }}{64}{figure.caption.21}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Active timing margin can save power effectively. However, the benefits decrease as more cores are used to actively run the application.\relax }}{67}{figure.caption.22}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Power saving.}}}{67}{subfigure.3.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Energy reduction.}}}{67}{subfigure.3.2}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Active timing margin can improve performance by increasing frequency. However, the overclocking benefits decrease as more cores are used.\relax }}{69}{figure.caption.23}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Overclocking mode.}}}{69}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Execution time.}}}{69}{subfigure.4.2}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Improvements reduce at different rates for each of the PARSEC and SPLASH-2 workloads when cores are progressively activated, leading to magnified workload variation when all cores are active.\relax }}{71}{figure.caption.24}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Undervolting mode.}}}{71}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Overclocking mode.}}}{71}{subfigure.5.2}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Mapping between on-chip voltage and CPM values.\relax }}{75}{figure.caption.25}
\contentsline {figure}{\numberline {4.7}{\ignorespaces CPMs can sense the chip supply voltage with a precision of about 21mV per CPM bit at peak frequency.\relax }}{76}{figure.caption.26}
\contentsline {figure}{\numberline {4.8}{\ignorespaces On-chip voltage drop analysis across cores under different workloads.\relax }}{77}{figure.caption.27}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Voltage drop component analysis, including $di/dt$ droop, IR drop and the loadline effect.\relax }}{80}{figure.caption.28}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Different components of on-chip voltage drop for some PARSEC and SPLASH-2 benchmarks. In general, as more of the processor's cores are activated, voltage drop increases by varying magnitudes across workloads.\relax }}{82}{figure.caption.29}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {raytrace.}}}{82}{subfigure.10.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {blackscholes.}}}{82}{subfigure.10.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {bodytrack.}}}{82}{subfigure.10.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {swaptions.}}}{82}{subfigure.10.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {vips.}}}{82}{subfigure.10.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {water\_nsquared.}}}{82}{subfigure.10.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {ferret.}}}{82}{subfigure.10.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {lu\_ncb.}}}{82}{subfigure.10.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {ocean\_cp.}}}{82}{subfigure.10.9}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Power-intensive workloads induce large loadline and IR drop, which severely limits the active timing margin system's undervolting capability, and thus impacts the system's overall power-saving potential.\relax }}{84}{figure.caption.30}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{84}{subfigure.11.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{84}{subfigure.11.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{84}{subfigure.11.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{84}{subfigure.11.4}
\contentsline {figure}{\numberline {4.12}{\ignorespaces Loadline borrowing balances workloads across multiple sockets to reduce per-socket voltage drop and create room for active timing margin.\relax }}{86}{figure.caption.31}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Workload consolidation.}}}{86}{subfigure.12.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Loadline borrowing.}}}{86}{subfigure.12.2}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Distributing {\it raytrace} across two processors reduces passive voltage drop, allowing more power saving under high core count.\relax }}{88}{figure.caption.32}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Undervolt scaling.}}}{88}{subfigure.13.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Power scaling.}}}{88}{subfigure.13.2}
\contentsline {figure}{\numberline {4.14}{\ignorespaces Loadline borrowing's power and energy improvement under different numbers of active cores. Compared to the baseline, loadline borrowing consistently shifts up every workload's power improvement.\relax }}{90}{figure.caption.33}
\contentsline {figure}{\numberline {4.15}{\ignorespaces Loadline borrowing's power and energy improvement when eight cores are active.\relax }}{91}{figure.caption.34}
\addvspace {10pt}
\contentsline {figure}{\numberline {5.1}{\ignorespaces \texttt {SqueezeNet} inference latency on a POWER7+ core under different timing margin settings. Aggressively customizing Active Timing Margin, and co-locating it with ``friendly'' low-power applications enhance performance.\relax }}{95}{figure.caption.35}
\contentsline {figure}{\numberline {5.2}{\ignorespaces CPM's inserted delay can be set by programming the number of inverters used~\cite {drake2007distributed, drake2013single}. Reducing the added delay makes the CPM count more time margin after a signal travels through the synthetic path which simulates real circuit toggling. The DPLL then increases frequency to harvest the excess margin reported by CPM's inverter chain.\relax }}{124}{figure.caption.36}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {CPM structure: programming the inserted delay sets the margin sensed by the inverter chain.}}}{124}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Reducing inserted delay increases ATM frequency.}}}{124}{subfigure.2.2}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Our ATM characterization methodology iterates over each core and follows a step-by step approach, going from the simplest system idle scenario to the complex real-world workloads.\relax }}{125}{figure.caption.37}
\contentsline {figure}{\numberline {5.4}{\ignorespaces The limit configuration of each POWER7+ core (i.e., the most aggressive reduction of CPM's inserted delay from its default setting, beyond which ATM operation can cause system failure under idle condition) distributes over a narrow range (red bar, left y axis). The operating frequency at each core's limit delay config is over 4800~MHz, more than 15\% higher than static margin's 4200~MHz level (blue mark, right y axis).\relax }}{126}{figure.caption.38}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {p0 core 0.}}}{126}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {p0 core 1.}}}{126}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {p0 core 2.}}}{126}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {p0 core 3.}}}{126}{subfigure.4.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {p0 core 4.}}}{126}{subfigure.4.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {p0 core 5.}}}{126}{subfigure.4.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {p0 core 6.}}}{126}{subfigure.4.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {p0 core 7.}}}{126}{subfigure.4.8}
\contentsline {subfigure}{\numberline {(i)}{\ignorespaces {p1 core 0.}}}{126}{subfigure.4.9}
\contentsline {subfigure}{\numberline {(j)}{\ignorespaces {p1 core 1.}}}{126}{subfigure.4.10}
\contentsline {subfigure}{\numberline {(k)}{\ignorespaces {p1 Core 2.}}}{126}{subfigure.4.11}
\contentsline {subfigure}{\numberline {(l)}{\ignorespaces {p1 Core 3.}}}{126}{subfigure.4.12}
\contentsline {subfigure}{\numberline {(m)}{\ignorespaces {p1 Core 4.}}}{126}{subfigure.4.13}
\contentsline {subfigure}{\numberline {(n)}{\ignorespaces {p1 Core 5.}}}{126}{subfigure.4.14}
\contentsline {subfigure}{\numberline {(o)}{\ignorespaces {p1 Core 6.}}}{126}{subfigure.4.15}
\contentsline {subfigure}{\numberline {(p)}{\ignorespaces {p1 Core 7.}}}{126}{subfigure.4.16}
\contentsline {figure}{\numberline {5.5}{\ignorespaces For 6 out of 16 cores, ATM configuration (i.e., CPM's inserted delay setting) needs to be rolled back from its idle limit in order for micro-benchmark (uBench) to run successfully. The FP (\texttt {daxpy}), MEM (\texttt {stream}), and INT (\texttt {coremark}) uBench have similar distribution of their pass config, indicating the core's mismatch between its reconfigured CPM timing measurement and its actual circuit speed. The other 10 cores not shown can run uBench safely at their idle limits.\relax }}{127}{figure.caption.40}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {p0 core3, \texttt {daxpy}}}}{127}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {p0 core4, \texttt {daxpy}}}}{127}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {p1 core3, \texttt {stream}}}}{127}{subfigure.5.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {p1 core4, \texttt {stream}}}}{127}{subfigure.5.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {p1 core5, \texttt {coremark}}}}{127}{subfigure.5.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {p1 core7, \texttt {coremark}}}}{127}{subfigure.5.6}
\contentsline {figure}{\numberline {5.6}{\ignorespaces \texttt {x264} stresses ATM more heavily and needs a more conservative CPM configuration compared to \texttt {gcc}, as indicated by the larger CPM rollback that is required for \texttt {x264} over \texttt {gcc}.\relax }}{127}{figure.caption.41}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {P0C3}}}{127}{subfigure.6.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {P1C6}}}{127}{subfigure.6.2}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Application's average CPM delay rollback from the core's uBench limit. The top workloads stress ATM heavily and need more delay rollback for less aggressive margin reclamation.\relax }}{128}{figure.caption.43}
\contentsline {figure}{\numberline {5.8}{\ignorespaces Aggressive ATM customization expose wide frequency variation, causing performance unpredictability.\relax }}{128}{figure.caption.44}
\contentsline {figure}{\numberline {5.9}{\ignorespaces After ATM customization, core frequency can be predicted with a fitted linear model, following Equation.~\ref {eq:freq-pred}.\relax }}{128}{figure.caption.44}
\contentsline {figure}{\numberline {5.10}{\ignorespaces Single-thread application performance can be predicted linearly using core frequency.\relax }}{128}{figure.caption.44}
\contentsline {figure}{\numberline {5.11}{\ignorespaces Aggressively configured ATM cores exhibit different CPM rollback steps and frequencies when running realistic workloads.\relax }}{129}{figure.caption.45}
\contentsline {figure}{\numberline {5.12}{\ignorespaces Managing a customized ATM system needs to integrate the per-app performance predictor and per-core frequency predictor, so that \texttt {critical} application performance can be satifised by using faster cores and maintaining an estimated chip power budget.\relax }}{129}{figure.caption.46}
\contentsline {figure}{\numberline {5.13}{\ignorespaces \texttt {Critical} application performance co-located with \texttt {background} workloads under different settings, shown as $<\tmspace -\thinmuskip {.1667em}critical:background\tmspace -\thinmuskip {.1667em}>$ pairs. Aggressively customized ATM, together with low-power co-running \texttt {background} workloads, boosts performance by 15.4\% on average. With proper management, a 10\% performance improvement goal is guaranteed for \texttt {critical workloads} by throttling co-runner's core frequency to main total chip power below budget.\relax }}{130}{figure.caption.48}
\addvspace {10pt}
